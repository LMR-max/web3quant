"""éªŒè¯ Agent ç³»ç»Ÿé…ç½®æ˜¯å¦æ­£ç¡®

æ”¯æŒä¸‰ç§åç«¯ï¼šgithub / foundry / openai

ç”¨æ³•ï¼š
    python agents/test_config.py
"""

import sys
import os

sys.path.insert(0, os.path.abspath(os.path.join(os.path.dirname(__file__), "..")))

from agents.config import (
    LLM_BACKEND,
    GITHUB_TOKEN,
    GITHUB_MODEL_ID,
    AZURE_OPENAI_ENDPOINT,
    AZURE_OPENAI_API_KEY,
    AZURE_OPENAI_DEPLOYMENT,
    AZURE_OPENAI_API_VERSION,
    OPENAI_API_KEY,
    OPENAI_MODEL_ID,
)


def check_config():
    """æ£€æŸ¥é…ç½®æ˜¯å¦å®Œæ•´"""
    print("=" * 60)
    print(f"é…ç½®æ£€æŸ¥  |  åç«¯æ¨¡å¼: {LLM_BACKEND.upper()}")
    print("=" * 60)

    issues = []

    if LLM_BACKEND == "github":
        # â”€â”€ GitHub Models â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if not GITHUB_TOKEN:
            issues.append("âŒ GITHUB_TOKEN æœªé…ç½®")
            issues.append("   â†’ https://github.com/settings/personal-access-tokens/new åˆ›å»º Fine-grained Token")
        else:
            masked = GITHUB_TOKEN[:8] + "..." + GITHUB_TOKEN[-4:]
            print(f"âœ… GITHUB_TOKEN: {masked}")
        print(f"âœ… æ¨¡å‹: {GITHUB_MODEL_ID}")
        print(f"âœ… ç«¯ç‚¹: https://models.inference.ai.azure.com")

    elif LLM_BACKEND == "foundry":
        # â”€â”€ Azure AI Foundry â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if not AZURE_OPENAI_ENDPOINT:
            issues.append("âŒ AZURE_OPENAI_ENDPOINT æœªé…ç½®")
        else:
            print(f"âœ… AZURE_OPENAI_ENDPOINT: {AZURE_OPENAI_ENDPOINT}")
            if not AZURE_OPENAI_ENDPOINT.endswith('/'):
                issues.append("âš ï¸  Endpoint åº”è¯¥ä»¥ '/' ç»“å°¾")
        if not AZURE_OPENAI_API_KEY:
            print("âš ï¸  AZURE_OPENAI_API_KEY æœªé…ç½®ï¼ˆå°†ä½¿ç”¨ az login å‡­æ®ï¼‰")
        else:
            print(f"âœ… AZURE_OPENAI_API_KEY: {AZURE_OPENAI_API_KEY[:10]}...")
        print(f"âœ… AZURE_OPENAI_DEPLOYMENT: {AZURE_OPENAI_DEPLOYMENT}")
        print(f"âœ… AZURE_OPENAI_API_VERSION: {AZURE_OPENAI_API_VERSION}")

    elif LLM_BACKEND == "openai":
        # â”€â”€ OpenAI ç›´è¿ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
        if not OPENAI_API_KEY:
            issues.append("âŒ OPENAI_API_KEY æœªé…ç½®")
            issues.append("   â†’ https://platform.openai.com/api-keys è·å–")
        else:
            print(f"âœ… OPENAI_API_KEY: {OPENAI_API_KEY[:8]}...")
        print(f"âœ… æ¨¡å‹: {OPENAI_MODEL_ID}")

    else:
        issues.append(f"âŒ æœªçŸ¥çš„ LLM_BACKEND: {LLM_BACKEND}")
        issues.append("   â†’ æ”¯æŒçš„å€¼: github, foundry, openai")

    print("\n" + "=" * 60)

    if issues:
        print("å‘ç°é—®é¢˜ï¼š")
        for issue in issues:
            print(f"  {issue}")
        print("\nè¯·æ£€æŸ¥ agents/.env æ–‡ä»¶é…ç½®")
        return False
    else:
        print("âœ… é…ç½®æ£€æŸ¥é€šè¿‡ï¼")
        return True


def test_client():
    """æµ‹è¯• Chat Client åˆ›å»º"""
    print("\n" + "=" * 60)
    print("æµ‹è¯• Chat Client åˆ›å»º")
    print("=" * 60)
    
    try:
        from agents.main import create_chat_client
        client = create_chat_client()
        print(f"âœ… Chat Client åˆ›å»ºæˆåŠŸï¼š{type(client).__name__}")
        return True
    except Exception as e:
        print(f"âŒ Chat Client åˆ›å»ºå¤±è´¥ï¼š{e}")
        return False


def test_workflow():
    """æµ‹è¯•å·¥ä½œæµæ„å»º"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•å·¥ä½œæµæ„å»º")
    print("=" * 60)
    
    try:
        from agents.main import build_optimization_workflow
        workflow = build_optimization_workflow()
        print(f"âœ… å·¥ä½œæµæ„å»ºæˆåŠŸï¼š{type(workflow).__name__}")
        print(f"   åŒ…å« 6 ä¸ªä¸“ä¸š Agent")
        return True
    except Exception as e:
        print(f"âŒ å·¥ä½œæµæ„å»ºå¤±è´¥ï¼š{e}")
        return False


def main():
    """è¿è¡Œæ‰€æœ‰æµ‹è¯•"""
    print("\nğŸ” Web3Quant Agent ç³»ç»Ÿé…ç½®éªŒè¯\n")
    
    config_ok = check_config()
    if not config_ok:
        print("\nâŒ é…ç½®æ£€æŸ¥æœªé€šè¿‡ï¼Œè¯·å…ˆä¿®å¤é…ç½®é—®é¢˜ã€‚")
        print("\nğŸ’¡ æç¤ºï¼š")
        if LLM_BACKEND == "github" or not LLM_BACKEND:
            print("   ã€æ¨èã€‘GitHub Modelsï¼ˆå…è´¹ã€æ— éœ€éƒ¨ç½²ï¼‰ï¼š")
            print("   1. å¤åˆ¶ agents/.env.github.example ä¸º agents/.env")
            print("   2. å» https://github.com/settings/tokens åˆ›å»º Token")
            print("   3. å¡«å…¥ GITHUB_TOKEN")
        else:
            print(f"   å½“å‰åç«¯: {LLM_BACKEND}")
            print("   è¯¦ç»†è¯´æ˜è§ agents/FOUNDRY_SETUP.md")
        sys.exit(1)
    
    client_ok = test_client()
    if not client_ok:
        print("\nâŒ Chat Client åˆ›å»ºå¤±è´¥")
        sys.exit(1)
    
    workflow_ok = test_workflow()
    if not workflow_ok:
        print("\nâŒ å·¥ä½œæµæ„å»ºå¤±è´¥")
        sys.exit(1)
    
    print("\n" + "=" * 60)
    print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼ç³»ç»Ÿå·²å°±ç»ªã€‚")
    print("=" * 60)
    print("\nä¸‹ä¸€æ­¥ï¼š")
    print("  â€¢ CLI æ¨¡å¼ï¼špython agents/main.py --cli")
    print("  â€¢ Server æ¨¡å¼ï¼špython agents/main.py --server")
    print("  â€¢ VS Code è°ƒè¯•ï¼šæŒ‰ F5 â†’ é€‰æ‹© 'Debug Agent Optimization Server'")
    print()


if __name__ == "__main__":
    main()
