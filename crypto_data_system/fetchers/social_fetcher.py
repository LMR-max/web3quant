"""
ç¤¾äº¤åª’ä½“æ•°æ®è·å–å™¨æ¨¡å—
ç”¨äºè·å–åŠ å¯†è´§å¸ç›¸å…³çš„ç¤¾äº¤åª’ä½“æ•°æ®ï¼ˆTwitter, Reddit, Telegramç­‰ï¼‰
"""

import time
import asyncio
import re
import json
from typing import Dict, List, Optional, Any, Union, Callable
from datetime import datetime, timedelta
import pandas as pd
import logging

try:
    from .base_fetcher import BaseFetcher, AsyncFetcher
    from ..data_models import SocialSentimentData, SocialPostData, SocialSentiment
except ImportError:
    # å¦‚æœç›´æ¥è¿è¡Œï¼Œä½¿ç”¨ç®€å•å¯¼å…¥
    import sys
    import os
    sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
    from fetchers.base_fetcher import BaseFetcher, AsyncFetcher
    from data_models import SocialSentimentData, SocialPostData, SocialSentiment


# ==================== ç¤¾äº¤åª’ä½“é…ç½® ====================

class SocialConfig:
    """ç¤¾äº¤åª’ä½“é…ç½®"""
    
    # Twitteré…ç½®
    TWITTER_API_KEY = None
    TWITTER_API_SECRET = None
    TWITTER_ACCESS_TOKEN = None
    TWITTER_ACCESS_SECRET = None
    TWITTER_BEARER_TOKEN = None
    
    # Reddité…ç½®
    REDDIT_CLIENT_ID = None
    REDDIT_CLIENT_SECRET = None
    REDDIT_USER_AGENT = None
    REDDIT_USERNAME = None
    REDDIT_PASSWORD = None
    
    # Telegramé…ç½®
    TELEGRAM_API_ID = None
    TELEGRAM_API_HASH = None
    TELEGRAM_BOT_TOKEN = None
    
    # é€šç”¨é…ç½®
    RATE_LIMIT = 1.0  # è¯·æ±‚é—´éš”ï¼ˆç§’ï¼‰
    MAX_RETRIES = 3
    TIMEOUT = 30
    PROXY_URL = None
    ENABLE_CACHE = True
    CACHE_TTL = 3600  # ç¼“å­˜æ—¶é—´ï¼ˆç§’ï¼‰


# ==================== ç¤¾äº¤åª’ä½“æ•°æ®æ¨¡å‹ ====================

class SocialData:
    """ç¤¾äº¤åª’ä½“æ•°æ®å®¹å™¨"""
    
    def __init__(self):
        self.posts = []
        self.metrics = {}  # Dict[str, SocialSentimentData]
        self.sentiment = None
        self.trends = []
        self.influencers = []
        self.last_update = datetime.now()
    
    def add_post(self, post: SocialPostData):
        """æ·»åŠ å¸–å­"""
        self.posts.append(post)
    
    def update_metrics(self, symbol: str, metrics: Any):
        """æ›´æ–°æŒ‡æ ‡"""
        self.metrics[symbol] = metrics
    
    def set_sentiment(self, sentiment: SocialSentimentData):
        """è®¾ç½®æƒ…ç»ª"""
        self.sentiment = sentiment
    
    def add_trend(self, trend: Dict[str, Any]):
        """æ·»åŠ è¶‹åŠ¿"""
        self.trends.append(trend)
    
    def add_influencer(self, influencer: Dict[str, Any]):
        """æ·»åŠ å½±å“è€…"""
        self.influencers.append(influencer)
    
    def to_dict(self) -> Dict[str, Any]:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'post_count': len(self.posts),
            'metrics': {k: (v.to_dict() if hasattr(v, 'to_dict') else v) for k, v in self.metrics.items()},
            'sentiment': self.sentiment.to_dict() if self.sentiment else None,
            'trends': self.trends,
            'influencers': self.influencers,
            'last_update': self.last_update.isoformat()
        }
    
    def to_dataframe(self) -> pd.DataFrame:
        """è½¬æ¢ä¸ºDataFrame"""
        if not self.posts:
            return pd.DataFrame()
        
        data = []
        for post in self.posts:
            # support both old and new object attrs just in case, but prefer new
            likes = getattr(post, 'like_count', getattr(post, 'likes', 0))
            shares = getattr(post, 'share_count', getattr(post, 'shares', 0))
            comments = getattr(post, 'reply_count', getattr(post, 'comments', 0))
            
            data.append({
                'id': post.post_id,
                'platform': getattr(post, 'platform', 'unknown'),
                'symbol': getattr(post, 'symbol', ''),
                'user': post.author_id,
                'username': post.author_name,
                'text': post.text[:100],
                'likes': likes,
                'shares': shares,
                'comments': comments,
                'timestamp': post.timestamp,
                'sentiment': getattr(post, 'sentiment', 'neutral'), # derived usually
                'sentiment_score': post.sentiment_score,
                'url': post.urls[0] if post.urls else ''
            })
        
        return pd.DataFrame(data)


# ==================== åŸºç¡€ç¤¾äº¤åª’ä½“è·å–å™¨ ====================

class BaseSocialFetcher(BaseFetcher):
    """
    åŸºç¡€ç¤¾äº¤åª’ä½“è·å–å™¨
    æ”¯æŒTwitterã€Redditã€Telegramç­‰å¹³å°
    """
    
    def __init__(self, 
                 name: str = "social_fetcher",
                 platform: str = "twitter",
                 config: Optional[Dict] = None,
                 **kwargs):
        """
        åˆå§‹åŒ–ç¤¾äº¤åª’ä½“è·å–å™¨
        
        å‚æ•°:
            name: è·å–å™¨åç§°
            platform: å¹³å°åç§° (twitter, reddit, telegram)
            config: é…ç½®å­—å…¸
            **kwargs: é¢å¤–å‚æ•°
        """
        super().__init__(exchange="social", market_type=platform, **kwargs)
        
        self.platform = platform
        self.social_config = self._load_social_config(config)
        
        # å¹³å°å®¢æˆ·ç«¯
        self.client = None
        self.is_authenticated = False
        
        # ç¤¾äº¤åª’ä½“ç‰¹å®šç»Ÿè®¡
        self.post_count = 0
        self.user_count = 0
        self.sentiment_analyzed = 0
        
        self.logger.info(f"åˆå§‹åŒ–ç¤¾äº¤åª’ä½“è·å–å™¨: {name}, å¹³å°: {platform}")

    def get_available_symbols(self) -> List[str]:
        """å‰ç«¯ç”¨äºâ€œåŠ è½½äº¤æ˜“å¯¹â€çš„å¯é€‰é¡¹ã€‚

        è¿™é‡Œçš„ symbol è¡¨ç¤ºåŠ å¯†è´§å¸ç¬¦å·ï¼ˆå¦‚ BTC/ETHï¼‰ï¼Œç”¨äºç¤¾äº¤çƒ­åº¦/æƒ…ç»ªèšåˆã€‚
        """
        return [
            'BTC', 'ETH', 'BNB', 'SOL', 'XRP', 'ADA', 'DOGE', 'TRX', 'AVAX', 'DOT',
            'MATIC', 'LINK', 'LTC', 'BCH', 'ATOM', 'UNI', 'AAVE', 'SUI', 'OP', 'ARB'
        ]
    
    def _load_social_config(self, config: Optional[Dict]) -> Dict:
        """åŠ è½½ç¤¾äº¤åª’ä½“é…ç½®"""
        if config is None:
            config = {}
        
        # åŠ è½½é»˜è®¤é…ç½®
        default_config = {
            'rate_limit': 1.0,
            'max_retries': 3,
            'timeout': 30,
            'proxy_url': None,
            'enable_cache': True,
            'cache_ttl': 3600,
            'max_posts': 100,
            'max_users': 50,
            'min_likes': 1,
            'min_followers': 100,
            'language': 'en',
            'keywords': ['crypto', 'bitcoin', 'ethereum', 'blockchain'],
            'symbols': ['BTC', 'ETH', 'XRP', 'ADA', 'DOGE'],
            'sentiment_enabled': True,
            'trend_analysis': True,
            'influencer_detection': True,
        }
        
        # åˆå¹¶é…ç½®
        for key, value in default_config.items():
            if key not in config:
                config[key] = value
        
        return config
    
    def _init_exchange(self):
        """åˆå§‹åŒ–ç¤¾äº¤åª’ä½“å¹³å°è¿æ¥ï¼ˆå®ç°æŠ½è±¡æ–¹æ³•ï¼‰"""
        try:
            self.logger.info(f"åˆå§‹åŒ–ç¤¾äº¤åª’ä½“å¹³å°: {self.platform}")
            # ç¤¾äº¤åª’ä½“å¹³å°åˆå§‹åŒ–åœ¨ authenticate ä¸­å®Œæˆ
            self.authenticate()
        except Exception as e:
            self.logger.error(f"åˆå§‹åŒ–ç¤¾äº¤åª’ä½“å¹³å°å¤±è´¥: {e}")
    
    def authenticate(self) -> bool:
        """
        è®¤è¯ç¤¾äº¤åª’ä½“å¹³å°
        
        è¿”å›:
            è®¤è¯æ˜¯å¦æˆåŠŸ
        """
        try:
            if self.platform == "twitter":
                success = self._authenticate_twitter()
            elif self.platform == "reddit":
                success = self._authenticate_reddit()
            elif self.platform == "telegram":
                success = self._authenticate_telegram()
            else:
                self.logger.error(f"ä¸æ”¯æŒçš„å¹³å°: {self.platform}")
                return False
            
            if success:
                self.is_authenticated = True
                self.logger.info(f"{self.platform} è®¤è¯æˆåŠŸ")
            else:
                self.logger.error(f"{self.platform} è®¤è¯å¤±è´¥")
            
            return success
            
        except Exception as e:
            self.logger.error(f"è®¤è¯å¤±è´¥: {e}")
            return False
    
    def _authenticate_twitter(self) -> bool:
        """è®¤è¯Twitter"""
        try:
            # å°è¯•å¯¼å…¥tweepy
            import tweepy
            
            # æ£€æŸ¥é…ç½®
            if not self.social_config.get('twitter_api_key'):
                self.logger.warning("Twitter APIå¯†é’¥æœªé…ç½®ï¼Œä½¿ç”¨æœ‰é™åŠŸèƒ½")
                return True  # éƒ¨åˆ†åŠŸèƒ½å¯èƒ½ä¸éœ€è¦è®¤è¯
            
            # åˆ›å»ºè®¤è¯å¯¹è±¡
            auth = tweepy.OAuth1UserHandler(
                self.social_config.get('twitter_api_key'),
                self.social_config.get('twitter_api_secret'),
                self.social_config.get('twitter_access_token'),
                self.social_config.get('twitter_access_secret')
            )
            
            # åˆ›å»ºAPIå®¢æˆ·ç«¯
            self.client = tweepy.API(auth, wait_on_rate_limit=True)
            
            # æµ‹è¯•è¿æ¥
            if self.social_config.get('twitter_bearer_token'):
                # ä½¿ç”¨v2 API
                self.client_v2 = tweepy.Client(
                    bearer_token=self.social_config.get('twitter_bearer_token'),
                    wait_on_rate_limit=True
                )
            
            return True
            
        except ImportError:
            self.logger.error("tweepyåº“æœªå®‰è£…ï¼Œè¯·ä½¿ç”¨: pip install tweepy")
            return False
        except Exception as e:
            self.logger.error(f"Twitterè®¤è¯å¤±è´¥: {e}")
            return False
    
    def _authenticate_reddit(self) -> bool:
        """è®¤è¯Reddit"""
        try:
            # å°è¯•å¯¼å…¥praw
            import praw
            
            # æ£€æŸ¥é…ç½®
            if not self.social_config.get('reddit_client_id'):
                self.logger.warning("Redditå®¢æˆ·ç«¯IDæœªé…ç½®ï¼Œä½¿ç”¨æœ‰é™åŠŸèƒ½")
                return True
            
            # åˆ›å»ºRedditå®ä¾‹
            self.client = praw.Reddit(
                client_id=self.social_config.get('reddit_client_id'),
                client_secret=self.social_config.get('reddit_client_secret'),
                user_agent=self.social_config.get('reddit_user_agent', 'CryptoSocialFetcher/1.0'),
                username=self.social_config.get('reddit_username'),
                password=self.social_config.get('reddit_password')
            )
            
            return True
            
        except ImportError:
            self.logger.error("prawåº“æœªå®‰è£…ï¼Œè¯·ä½¿ç”¨: pip install praw")
            return False
        except Exception as e:
            self.logger.error(f"Redditè®¤è¯å¤±è´¥: {e}")
            return False
    
    def _authenticate_telegram(self) -> bool:
        """è®¤è¯Telegram"""
        try:
            # å°è¯•å¯¼å…¥telethon
            from telethon import TelegramClient
            
            # æ£€æŸ¥é…ç½®
            if not self.social_config.get('telegram_api_id'):
                self.logger.warning("Telegram API IDæœªé…ç½®ï¼Œä½¿ç”¨æœ‰é™åŠŸèƒ½")
                return True
            
            # åˆ›å»ºTelegramå®¢æˆ·ç«¯
            self.client = TelegramClient(
                'crypto_social_fetcher',
                self.social_config.get('telegram_api_id'),
                self.social_config.get('telegram_api_hash')
            )
            
            # å¯åŠ¨å®¢æˆ·ç«¯ï¼ˆéœ€è¦åœ¨å¤–éƒ¨è°ƒç”¨start()ï¼‰
            return True
            
        except ImportError:
            self.logger.error("telethonåº“æœªå®‰è£…ï¼Œè¯·ä½¿ç”¨: pip install telethon")
            return False
        except Exception as e:
            self.logger.error(f"Telegramè®¤è¯å¤±è´¥: {e}")
            return False
    
    def fetch_posts(self, 
                   query: str = None,
                   symbol: str = None,
                   since: Optional[datetime] = None,
                   until: Optional[datetime] = None,
                   limit: int = 100,
                   **kwargs) -> List[SocialPostData]:
        """
        è·å–ç¤¾äº¤åª’ä½“å¸–å­
        
        å‚æ•°:
            query: æœç´¢æŸ¥è¯¢
            symbol: åŠ å¯†è´§å¸ç¬¦å·
            since: å¼€å§‹æ—¶é—´
            until: ç»“æŸæ—¶é—´
            limit: æœ€å¤§å¸–å­æ•°é‡
            **kwargs: é¢å¤–å‚æ•°
            
        è¿”å›:
            å¸–å­åˆ—è¡¨
        """
        # æ„å»ºæŸ¥è¯¢
        if not query and symbol:
            query = self._build_query_from_symbol(symbol)
        
        if not query:
            query = " ".join(self.social_config.get('keywords', []))
        
        # è°ƒç”¨å¹³å°ç‰¹å®šæ–¹æ³•
        if self.platform == "twitter":
            return self._fetch_twitter_posts(query, since, until, limit, **kwargs)
        elif self.platform == "reddit":
            return self._fetch_reddit_posts(query, since, until, limit, **kwargs)
        elif self.platform == "telegram":
            return self._fetch_telegram_posts(query, since, until, limit, **kwargs)
        else:
            self.logger.error(f"ä¸æ”¯æŒçš„å¹³å°: {self.platform}")
            return []
    
    def _build_query_from_symbol(self, symbol: str) -> str:
        """ä»ç¬¦å·æ„å»ºæŸ¥è¯¢"""
        # åŠ å¯†è´§å¸ç¬¦å·æ˜ å°„
        crypto_terms = {
            'BTC': ['bitcoin', 'btc', '#bitcoin', '#btc'],
            'ETH': ['ethereum', 'eth', '#ethereum', '#eth'],
            'XRP': ['ripple', 'xrp', '#ripple', '#xrp'],
            'ADA': ['cardano', 'ada', '#cardano', '#ada'],
            'DOGE': ['dogecoin', 'doge', '#dogecoin', '#doge'],
            'SOL': ['solana', 'sol', '#solana', '#sol'],
            'DOT': ['polkadot', 'dot', '#polkadot', '#dot'],
            'LINK': ['chainlink', 'link', '#chainlink', '#link'],
            'BNB': ['binance', 'bnb', '#binance', '#bnb'],
            'USDT': ['tether', 'usdt', '#tether', '#usdt'],
        }
        
        terms = crypto_terms.get(symbol.upper(), [symbol.lower()])
        return f"({' OR '.join(terms)}) crypto"
    
    def _fetch_twitter_posts(self, query: str, since: datetime, until: datetime, 
                           limit: int, **kwargs) -> List[SocialPostData]:
        """è·å–Twitterå¸–å­"""
        posts = []
        
        try:
            if not self.client:
                self.logger.warning("Twitterå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
                return posts
            
            # è®¡ç®—æœ€å¤§IDï¼ˆç”¨äºåˆ†é¡µï¼‰
            max_id = None
            tweet_count = 0
            
            while tweet_count < limit:
                try:
                    # æœç´¢æ¨æ–‡
                    tweets = self.client.search_tweets(
                        q=query,
                        count=min(100, limit - tweet_count),
                        since_id=max_id,
                        tweet_mode='extended'
                    )
                    
                    if not tweets:
                        break
                    
                    for tweet in tweets:
                        # è½¬æ¢ä¸ºSocialPostData
                        post = self._tweet_to_data(tweet)
                        posts.append(post)
                        tweet_count += 1
                        
                        # æ›´æ–°max_idç”¨äºåˆ†é¡µ
                        if max_id is None or tweet.id < max_id:
                            max_id = tweet.id - 1
                    
                    # é¢‘ç‡é™åˆ¶
                    time.sleep(self.social_config.get('rate_limit', 1.0))
                    
                except Exception as e:
                    self.logger.error(f"è·å–æ¨æ–‡å¤±è´¥: {e}")
                    break
            
            self.post_count += len(posts)
            self.logger.info(f"è·å– {len(posts)} æ¡Twitterå¸–å­")
            
        except Exception as e:
            self.logger.error(f"Twitterè·å–å¤±è´¥: {e}")
        
        return posts
    
    def _tweet_to_data(self, tweet) -> SocialPostData:
        """è½¬æ¢Tweetä¸ºSocialPostData"""
        # æå–æ–‡æœ¬
        text = tweet.full_text if hasattr(tweet, 'full_text') else tweet.text
        
        # åˆ†ææƒ…ç»ª
        sentiment, sentiment_score = self._analyze_sentiment(text)
        
        # æå–åŠ å¯†è´§å¸ç¬¦å·
        symbols = self._extract_symbols(text)
        
        # åˆ›å»ºå¸–å­å¯¹è±¡
        post = SocialPostData(
            post_id=str(tweet.id),
            timestamp=datetime.fromtimestamp(tweet.created_at_in_seconds) 
                       if hasattr(tweet, 'created_at_in_seconds') 
                       else pd.Timestamp(tweet.created_at),
            symbol=symbols[0] if symbols else '', # primary symbol
            exchange='twitter', # used as platform
            market_type='social',
            text=text,
            author_id=str(tweet.user.id),
            author_name=tweet.user.screen_name,
            like_count=tweet.favorite_count,
            share_count=tweet.retweet_count, # retweet as share
            reply_count=0,  # Twitter API simple object doesn't always have reply count easily
            sentiment_score=sentiment_score,
            urls=[f"https://twitter.com/{tweet.user.screen_name}/status/{tweet.id}"],
            hashtags=[hashtag['text'] for hashtag in tweet.entities.get('hashtags', [])],
            mentions=[mention['screen_name'] for mention in tweet.entities.get('user_mentions', [])],
            extra_info={'raw_data': tweet._json if hasattr(tweet, '_json') else str(tweet)}
        )
        
        return post
    
    def _fetch_reddit_posts(self, query: str, since: datetime, until: datetime,
                          limit: int, **kwargs) -> List[SocialPostData]:
        """è·å–Redditå¸–å­"""
        posts = []
        
        try:
            if not self.client:
                self.logger.warning("Redditå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
                return posts
            
            # æœç´¢subredditæˆ–ä½¿ç”¨é€šç”¨æœç´¢
            subreddit_name = kwargs.get('subreddit', 'all')
            sort_by = kwargs.get('sort_by', 'relevance')
            time_filter = kwargs.get('time_filter', 'all')
            
            # æœç´¢å¸–å­
            search_results = self.client.subreddit(subreddit_name).search(
                query=query,
                sort=sort_by,
                time_filter=time_filter,
                limit=limit
            )
            
            for submission in search_results:
                # è½¬æ¢ä¸ºSocialPostData
                post = self._reddit_submission_to_data(submission)
                posts.append(post)
            
            self.post_count += len(posts)
            self.logger.info(f"è·å– {len(posts)} æ¡Redditå¸–å­")
            
        except Exception as e:
            self.logger.error(f"Redditè·å–å¤±è´¥: {e}")
        
        return posts
    
    def _reddit_submission_to_data(self, submission) -> SocialPostData:
        """è½¬æ¢Redditæäº¤ä¸ºSocialPostData"""
        # åˆ†ææƒ…ç»ª
        text_content = submission.title + " " + submission.selftext
        sentiment, sentiment_score = self._analyze_sentiment(text_content)
        
        # æå–åŠ å¯†è´§å¸ç¬¦å·
        symbols = self._extract_symbols(text_content)
        
        # åˆ›å»ºå¸–å­å¯¹è±¡
        post = SocialPostData(
            post_id=str(submission.id),
            timestamp=pd.Timestamp(submission.created_utc, unit='s'),
            symbol=symbols[0] if symbols else '',
            exchange='reddit',
            market_type='social',
            text=submission.title + "\n\n" + submission.selftext,
            author_id=str(submission.author),
            author_name=str(submission.author),
            like_count=submission.score,
            share_count=0,
            reply_count=submission.num_comments,
            sentiment_score=sentiment_score,
            urls=[f"https://reddit.com{submission.permalink}"],
            extra_info={
                'subreddit': submission.subreddit.display_name,
                'upvote_ratio': submission.upvote_ratio,
                'sentiment_label': sentiment
            }
        )
        
        return post
    
    def _fetch_telegram_posts(self, query: str, since: datetime, until: datetime,
                            limit: int, **kwargs) -> List[SocialPostData]:
        """è·å–Telegramæ¶ˆæ¯"""
        posts = []
        
        try:
            if not self.client:
                self.logger.warning("Telegramå®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
                return posts
            
            # è·å–é¢‘é“æˆ–ç¾¤ç»„
            channel = kwargs.get('channel')
            group = kwargs.get('group')
            
            if not channel and not group:
                self.logger.warning("æœªæŒ‡å®šé¢‘é“æˆ–ç¾¤ç»„")
                return posts
            
            # è¿™é‡Œéœ€è¦å®é™…çš„Telegramå®¢æˆ·ç«¯å®ç°
            # ç”±äºTelegram APIçš„é™åˆ¶ï¼Œè¿™é‡Œåªæä¾›æ¡†æ¶
            
            self.logger.warning("Telegramè·å–åŠŸèƒ½éœ€è¦å®Œæ•´å®ç°telethonå®¢æˆ·ç«¯")
            
        except Exception as e:
            self.logger.error(f"Telegramè·å–å¤±è´¥: {e}")
        
        return posts
    
    def _analyze_sentiment(self, text: str) -> tuple:
        """
        åˆ†ææ–‡æœ¬æƒ…ç»ª
        
        å‚æ•°:
            text: æ–‡æœ¬
            
        è¿”å›:
            (æƒ…ç»ª, åˆ†æ•°) å…ƒç»„
        """
        if not self.social_config.get('sentiment_enabled', True):
            return "neutral", 0.0
        
        try:
            # ç®€å•çš„åŸºäºå…³é”®è¯çš„æƒ…ç»ªåˆ†æ
            positive_words = [
                'bullish', 'moon', 'ğŸš€', 'rocket', 'buy', 'long', 'ä¸Šæ¶¨', 'æ¶¨',
                'good', 'great', 'excellent', 'amazing', 'awesome', 'profit',
                'win', 'gain', 'success', 'çªç ´', 'æ–°é«˜', 'æš´æ¶¨'
            ]
            
            negative_words = [
                'bearish', 'dump', 'crash', 'sell', 'short', 'ä¸‹è·Œ', 'è·Œ',
                'bad', 'terrible', 'awful', 'horrible', 'loss', 'lose',
                'fail', 'failure', 'ç ´äº§', 'å½’é›¶', 'æš´è·Œ', 'å´©ç›˜'
            ]
            
            # è®¡ç®—æƒ…ç»ªåˆ†æ•°
            text_lower = text.lower()
            positive_count = sum(1 for word in positive_words if word.lower() in text_lower)
            negative_count = sum(1 for word in negative_words if word.lower() in text_lower)
            
            total = positive_count + negative_count
            if total == 0:
                return "neutral", 0.0
            
            score = (positive_count - negative_count) / total
            
            if score > 0.2:
                sentiment = "positive"
            elif score < -0.2:
                sentiment = "negative"
            else:
                sentiment = "neutral"
            
            self.sentiment_analyzed += 1
            return sentiment, score
            
        except Exception as e:
            self.logger.error(f"æƒ…ç»ªåˆ†æå¤±è´¥: {e}")
            return "neutral", 0.0
    
    def _extract_symbols(self, text: str) -> List[str]:
        """
        ä»æ–‡æœ¬ä¸­æå–åŠ å¯†è´§å¸ç¬¦å·
        
        å‚æ•°:
            text: æ–‡æœ¬
            
        è¿”å›:
            ç¬¦å·åˆ—è¡¨
        """
        symbols = []
        
        # å¸¸è§åŠ å¯†è´§å¸ç¬¦å·æ¨¡å¼
        patterns = [
            r'\$([A-Z]{2,5})\b',  # $BTC, $ETH
            r'\b([A-Z]{2,5})\b',  # BTC, ETH
            r'#([A-Z]{2,5})\b',   # #BTC, #ETH
        ]
        
        for pattern in patterns:
            matches = re.findall(pattern, text.upper())
            symbols.extend(matches)
        
        # å»é‡
        symbols = list(set(symbols))
        
        # è¿‡æ»¤å¸¸è§éåŠ å¯†è´§å¸ç¬¦å·
        common_words = ['THE', 'AND', 'FOR', 'ARE', 'YOU', 'ALL', 'NOT', 'BUT', 'HAS', 'WAS']
        symbols = [s for s in symbols if s not in common_words and len(s) <= 5]
        
        return symbols
    
    def fetch_metrics(self, 
                     symbol: str,
                     period: str = "24h",
                     **kwargs) -> SocialSentimentData:
        """
        è·å–ç¤¾äº¤åª’ä½“æŒ‡æ ‡ (è¿”å› SocialSentimentData)
        
        å‚æ•°:
            symbol: åŠ å¯†è´§å¸ç¬¦å·
            period: æ—¶é—´æ®µ (24h, 7d, 30d)
            **kwargs: é¢å¤–å‚æ•°
            
        è¿”å›:
            ç¤¾äº¤åª’ä½“æƒ…ç»ªæ•°æ®
        """
        try:
            # è·å–ç›¸å…³å¸–å­
            posts = self.fetch_posts(symbol=symbol, limit=100, **kwargs)
            
            if not posts:
                return SocialSentimentData(
                    timestamp=pd.Timestamp.now(),
                    symbol=symbol,
                    exchange="social",
                    market_type=self.platform,
                    platform=self.platform,
                    keyword=symbol
                )
            
            # è®¡ç®—æŒ‡æ ‡
            total_likes = sum(p.like_count for p in posts)
            total_shares = sum(p.share_count for p in posts)
            total_comments = sum(p.reply_count for p in posts)
            
            # æƒ…ç»ªåˆ†æ•°
            sentiment_scores = [p.sentiment_score for p in posts if p.sentiment_score is not None]
            avg_sentiment = sum(sentiment_scores) / len(sentiment_scores) if sentiment_scores else 0.0
            
            # ç»Ÿè®¡æ­£è´Ÿé¢
            positive_count = sum(1 for p in posts if p.sentiment_score > 0.2)
            negative_count = sum(1 for p in posts if p.sentiment_score < -0.2)
            neutral_count = len(posts) - positive_count - negative_count

            # å‚ä¸ç‡
            engagement_rate = (total_likes + total_shares + total_comments) / len(posts) if posts else 0.0
            
            # Top influencers extraction (simplified)
            # sort by engagement
            sorted_posts = sorted(posts, key=lambda x: (x.like_count + x.share_count), reverse=True)
            top_influencers = []
            seen_authors = set()
            for p in sorted_posts:
                if p.author_name and p.author_name not in seen_authors:
                    top_influencers.append({
                        'author_name': p.author_name,
                        'author_id': p.author_id,
                        'engagement': p.like_count + p.share_count
                    })
                    seen_authors.add(p.author_name)
                    if len(top_influencers) >= 5:
                        break

            # åˆ›å»ºæŒ‡æ ‡å¯¹è±¡
            metric = SocialSentimentData(
                timestamp=pd.Timestamp.now(),
                symbol=symbol,
                exchange="social",
                market_type=self.platform,
                platform=self.platform,
                keyword=symbol,
                sentiment_score=avg_sentiment,
                positive_count=positive_count,
                negative_count=negative_count,
                neutral_count=neutral_count,
                total_mentions=len(posts),
                engagement_rate=engagement_rate,
                top_influencers=top_influencers
            )
            
            self.logger.info(f"è·å– {symbol} ç¤¾äº¤åª’ä½“æŒ‡æ ‡: {len(posts)} æ¡å¸–å­, æƒ…ç»ªåˆ†: {avg_sentiment:.2f}")
            return metric
            
        except Exception as e:
            self.logger.error(f"è·å–æŒ‡æ ‡å¤±è´¥: {e}")
            return SocialSentimentData(
                timestamp=pd.Timestamp.now(),
                symbol=symbol,
                exchange="social",
                market_type=self.platform,
                platform=self.platform,
                keyword=symbol
            )
    
    def fetch_trends(self, 
                    limit: int = 10,
                    **kwargs) -> List[Dict[str, Any]]:
        """
        è·å–ç¤¾äº¤åª’ä½“è¶‹åŠ¿
        
        å‚æ•°:
            limit: æœ€å¤§è¶‹åŠ¿æ•°é‡
            **kwargs: é¢å¤–å‚æ•°
            
        è¿”å›:
            è¶‹åŠ¿åˆ—è¡¨
        """
        trends = []
        
        try:
            if self.platform == "twitter":
                # è·å–Twitterè¶‹åŠ¿
                if hasattr(self, 'client_v2') and self.client_v2:
                    # ä½¿ç”¨Twitter API v2è·å–è¶‹åŠ¿
                    pass
                    
            elif self.platform == "reddit":
                # è·å–Redditçƒ­é—¨è¯é¢˜
                if self.client:
                    for subreddit_name in ['cryptocurrency', 'bitcoin', 'ethereum']:
                        try:
                            subreddit = self.client.subreddit(subreddit_name)
                            for post in subreddit.hot(limit=5):
                                trends.append({
                                    'platform': 'reddit',
                                    'title': post.title,
                                    'subreddit': subreddit_name,
                                    'score': post.score,
                                    'comments': post.num_comments,
                                    'url': f"https://reddit.com{post.permalink}",
                                    'symbols': self._extract_symbols(post.title + " " + post.selftext)
                                })
                        except Exception as e:
                            self.logger.error(f"è·å–subreddit {subreddit_name} å¤±è´¥: {e}")
            
            self.logger.info(f"è·å– {len(trends)} æ¡è¶‹åŠ¿")
            
        except Exception as e:
            self.logger.error(f"è·å–è¶‹åŠ¿å¤±è´¥: {e}")
        
        return trends[:limit]
    
    def fetch_influencers(self, 
                         symbol: str = None,
                         limit: int = 10,
                         **kwargs) -> List[Dict[str, Any]]:
        """
        è·å–å½±å“è€…
        
        å‚æ•°:
            symbol: åŠ å¯†è´§å¸ç¬¦å·
            limit: æœ€å¤§å½±å“è€…æ•°é‡
            **kwargs: é¢å¤–å‚æ•°
            
        è¿”å›:
            å½±å“è€…åˆ—è¡¨
        """
        influencers = []
        
        try:
            if self.platform == "twitter":
                # è¿™é‡Œå¯ä»¥å®ç°Twitterå½±å“è€…åˆ†æ
                pass
                
            elif self.platform == "reddit":
                # åˆ†æRedditç”¨æˆ·
                if self.client and symbol:
                    # æœç´¢ç›¸å…³å¸–å­
                    posts = self.fetch_posts(symbol=symbol, limit=50, **kwargs)
                    
                    # ç»Ÿè®¡ç”¨æˆ·æ´»è·ƒåº¦
                    user_stats = {}
                    for post in posts:
                        user_id = post.user_id
                        if user_id not in user_stats:
                            user_stats[user_id] = {
                                'username': post.username,
                                'post_count': 0,
                                'total_likes': 0,
                                'total_comments': 0,
                                'avg_sentiment': 0.0
                            }
                        
                        user_stats[user_id]['post_count'] += 1
                        user_stats[user_id]['total_likes'] += post.likes
                        user_stats[user_id]['total_comments'] += post.comments
                    
                    # è½¬æ¢ä¸ºå½±å“è€…åˆ—è¡¨
                    for user_id, stats in user_stats.items():
                        if stats['post_count'] >= 2:  # è‡³å°‘2ä¸ªå¸–å­
                            influencers.append({
                                'platform': 'reddit',
                                'user_id': user_id,
                                'username': stats['username'],
                                'post_count': stats['post_count'],
                                'total_engagement': stats['total_likes'] + stats['total_comments'],
                                'symbol': symbol
                            })
                    
                    # æŒ‰å‚ä¸åº¦æ’åº
                    influencers.sort(key=lambda x: x['total_engagement'], reverse=True)
            
            self.user_count += len(influencers)
            self.logger.info(f"è·å– {len(influencers)} ä¸ªå½±å“è€…")
            
        except Exception as e:
            self.logger.error(f"è·å–å½±å“è€…å¤±è´¥: {e}")
        
        return influencers[:limit]
    
    def analyze_sentiment_over_time(self,
                                   symbol: str,
                                   days: int = 7,
                                   **kwargs) -> Dict[str, Any]:
        """
        åˆ†æä¸€æ®µæ—¶é—´å†…çš„æƒ…ç»ªå˜åŒ–
        
        å‚æ•°:
            symbol: åŠ å¯†è´§å¸ç¬¦å·
            days: å¤©æ•°
            **kwargs: é¢å¤–å‚æ•°
            
        è¿”å›:
            æƒ…ç»ªåˆ†æç»“æœ
        """
        results = {
            'symbol': symbol,
            'platform': self.platform,
            'days': days,
            'daily_sentiment': [],
            'overall_sentiment': 'neutral',
            'sentiment_score': 0.0,
            'total_posts': 0,
            'start_date': datetime.now() - timedelta(days=days),
            'end_date': datetime.now()
        }
        
        try:
            # æŒ‰å¤©è·å–æ•°æ®
            for i in range(days):
                day_start = datetime.now() - timedelta(days=i+1)
                day_end = datetime.now() - timedelta(days=i)
                
                # è·å–è¯¥å¤©çš„å¸–å­
                posts = self.fetch_posts(
                    symbol=symbol,
                    since=day_start,
                    until=day_end,
                    limit=50,
                    **kwargs
                )
                
                if posts:
                    # è®¡ç®—å½“å¤©æƒ…ç»ª
                    sentiment_scores = [p.sentiment_score for p in posts if p.sentiment_score is not None]
                    day_sentiment = sum(sentiment_scores) / len(sentiment_scores) if sentiment_scores else 0.0
                    
                    results['daily_sentiment'].append({
                        'date': day_start.strftime('%Y-%m-%d'),
                        'post_count': len(posts),
                        'sentiment_score': day_sentiment,
                        'sentiment': 'positive' if day_sentiment > 0.2 else 'negative' if day_sentiment < -0.2 else 'neutral'
                    })
            
            # è®¡ç®—æ€»ä½“æƒ…ç»ª
            if results['daily_sentiment']:
                total_score = sum(day['sentiment_score'] for day in results['daily_sentiment'])
                avg_score = total_score / len(results['daily_sentiment'])
                
                results['sentiment_score'] = avg_score
                results['total_posts'] = sum(day['post_count'] for day in results['daily_sentiment'])
                results['overall_sentiment'] = 'positive' if avg_score > 0.2 else 'negative' if avg_score < -0.2 else 'neutral'
            
            self.logger.info(f"åˆ†æ {symbol} {days}å¤©æƒ…ç»ªå˜åŒ–: {results['total_posts']} æ¡å¸–å­")
            
        except Exception as e:
            self.logger.error(f"æƒ…ç»ªæ—¶é—´åˆ†æå¤±è´¥: {e}")
        
        return results
    
    def fetch_comprehensive_data(self,
                               symbol: str,
                               **kwargs) -> SocialData:
        """
        è·å–å…¨é¢çš„ç¤¾äº¤åª’ä½“æ•°æ®
        
        å‚æ•°:
            symbol: åŠ å¯†è´§å¸ç¬¦å·
            **kwargs: é¢å¤–å‚æ•°
            
        è¿”å›:
            ç¤¾äº¤åª’ä½“æ•°æ®å®¹å™¨
        """
        social_data = SocialData()
        
        try:
            # è·å–å¸–å­
            posts = self.fetch_posts(symbol=symbol, **kwargs)
            for post in posts:
                social_data.add_post(post)
            
            # è·å–æŒ‡æ ‡
            metrics = self.fetch_metrics(symbol=symbol, **kwargs)
            social_data.update_metrics(symbol, metrics)
            
            # è·å–è¶‹åŠ¿
            trends = self.fetch_trends(**kwargs)
            for trend in trends:
                social_data.add_trend(trend)
            
            # è·å–å½±å“è€…
            influencers = self.fetch_influencers(symbol=symbol, **kwargs)
            for influencer in influencers:
                social_data.add_influencer(influencer)
            
            # åˆ†ææƒ…ç»ª
            sentiment_analysis = self.analyze_sentiment_over_time(symbol=symbol, **kwargs)
            # è®¡ç®—æ­£è´Ÿä¸­æ€§è®¡æ•°ï¼ˆä½¿ç”¨ sentiment_scoreï¼‰
            positive_count = sum(1 for p in posts if getattr(p, 'sentiment_score', None) is not None and p.sentiment_score > 0.2)
            negative_count = sum(1 for p in posts if getattr(p, 'sentiment_score', None) is not None and p.sentiment_score < -0.2)
            neutral_count = len(posts) - positive_count - negative_count

            sentiment = SocialSentiment(
                timestamp=pd.Timestamp.now(),
                symbol=symbol,
                platform=self.platform,
                overall_sentiment=sentiment_analysis.get('overall_sentiment', 'neutral'),
                sentiment_score=sentiment_analysis.get('sentiment_score', 0.0),
                confidence=0.8,
                positive_count=positive_count,
                negative_count=negative_count,
                neutral_count=neutral_count,
                total_mentions=len(posts),
                analysis_period=f"{sentiment_analysis.get('days', 0)}å¤©"
            )
            social_data.set_sentiment(sentiment)
            
            self.logger.info(f"è·å– {symbol} å…¨é¢ç¤¾äº¤åª’ä½“æ•°æ®: {len(posts)} æ¡å¸–å­")
            
        except Exception as e:
            self.logger.error(f"è·å–å…¨é¢æ•°æ®å¤±è´¥: {e}")
        
        return social_data
    
    # å®ç°æŠ½è±¡æ–¹æ³•ï¼ˆå¯¹äºç¤¾äº¤åª’ä½“ä¸é€‚ç”¨ï¼Œè¿”å›ç©ºæ•°æ®ï¼‰
    def fetch_ohlcv(self, symbol: str, timeframe: str = "1h", since=None, limit=None, **kwargs):
        """è·å–Kçº¿æ•°æ®ï¼ˆå¯¹äºç¤¾äº¤åª’ä½“ä¸é€‚ç”¨ï¼‰"""
        self.logger.warning(f"ç¤¾äº¤åª’ä½“è·å–å™¨ä¸æ”¯æŒOHLCVæ•°æ®")
        return []
    
    def fetch_orderbook(self, symbol: str, limit=None, **kwargs):
        """è·å–è®¢å•ç°¿æ•°æ®ï¼ˆå¯¹äºç¤¾äº¤åª’ä½“ä¸é€‚ç”¨ï¼‰"""
        self.logger.warning(f"ç¤¾äº¤åª’ä½“è·å–å™¨ä¸æ”¯æŒè®¢å•ç°¿æ•°æ®")
        return None
    
    def fetch_trades(self, symbol: str, since=None, limit=None, **kwargs):
        """è·å–æˆäº¤æ•°æ®ï¼ˆå¯¹äºç¤¾äº¤åª’ä½“ä¸é€‚ç”¨ï¼‰"""
        self.logger.warning(f"ç¤¾äº¤åª’ä½“è·å–å™¨ä¸æ”¯æŒæˆäº¤æ•°æ®")
        return []
    
    def get_available_symbols(self) -> List[str]:
        """è·å–å¯ç”¨ç¬¦å·ï¼ˆç¤¾äº¤åª’ä½“å…³æ³¨çš„æ‰€æœ‰åŠ å¯†è´§å¸ï¼‰"""
        return self.social_config.get('symbols', [])
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–è·å–å™¨çŠ¶æ€"""
        status = super().get_status()
        status.update({
            'platform': self.platform,
            'is_authenticated': self.is_authenticated,
            'post_count': self.post_count,
            'user_count': self.user_count,
            'sentiment_analyzed': self.sentiment_analyzed,
            'social_config': {
                'max_posts': self.social_config.get('max_posts'),
                'keywords': self.social_config.get('keywords'),
                'symbols': self.social_config.get('symbols'),
                'sentiment_enabled': self.social_config.get('sentiment_enabled'),
            }
        })
        return status
    
    def initialize(self):
        """åˆå§‹åŒ–è·å–å™¨"""
        if not self.is_authenticated:
            success = self.authenticate()
            if success:
                self.is_initialized = True
                return True
            return False
        return True
    
    def close(self):
        """å…³é—­è·å–å™¨"""
        if self.client:
            # æ¸…ç†å®¢æˆ·ç«¯èµ„æº
            if self.platform == "telegram" and hasattr(self.client, 'disconnect'):
                try:
                    self.client.disconnect()
                except:
                    pass
        
        super().close()


# ==================== å¤šå¹³å°ç¤¾äº¤åª’ä½“è·å–å™¨ ====================

class MultiPlatformSocialFetcher:
    """
    å¤šå¹³å°ç¤¾äº¤åª’ä½“è·å–å™¨
    åŒæ—¶ä»å¤šä¸ªå¹³å°è·å–æ•°æ®
    """
    
    def __init__(self, platforms: List[str] = None, config: Optional[Dict] = None):
        """
        åˆå§‹åŒ–å¤šå¹³å°è·å–å™¨
        
        å‚æ•°:
            platforms: å¹³å°åˆ—è¡¨
            config: é…ç½®å­—å…¸
        """
        self.platforms = platforms or ["twitter", "reddit"]
        self.config = config or {}
        
        # åˆå§‹åŒ–æ—¥å¿—
        self.logger = logging.getLogger("multi_platform_social_fetcher")
        
        # å¹³å°è·å–å™¨å­—å…¸
        self.fetchers = {}
        
        # åˆå§‹åŒ–çŠ¶æ€
        self.is_initialized = False
        
        self.logger.info(f"åˆå§‹åŒ–å¤šå¹³å°ç¤¾äº¤åª’ä½“è·å–å™¨: {', '.join(self.platforms)}")
    
    def initialize(self):
        """åˆå§‹åŒ–æ‰€æœ‰å¹³å°è·å–å™¨"""
        for platform in self.platforms:
            try:
                fetcher = BaseSocialFetcher(
                    name=f"social_{platform}",
                    platform=platform,
                    config=self.config.get(platform, {})
                )
                
                if fetcher.initialize():
                    self.fetchers[platform] = fetcher
                    self.logger.info(f"åˆå§‹åŒ– {platform} å¹³å°æˆåŠŸ")
                else:
                    self.logger.warning(f"åˆå§‹åŒ– {platform} å¹³å°å¤±è´¥")
                    
            except Exception as e:
                self.logger.error(f"åˆ›å»º {platform} è·å–å™¨å¤±è´¥: {e}")
        
        self.is_initialized = len(self.fetchers) > 0
        return self.is_initialized
    
    def fetch_multi_platform_data(self,
                                symbol: str,
                                **kwargs) -> Dict[str, SocialData]:
        """
        ä»å¤šä¸ªå¹³å°è·å–æ•°æ®
        
        å‚æ•°:
            symbol: åŠ å¯†è´§å¸ç¬¦å·
            **kwargs: é¢å¤–å‚æ•°
            
        è¿”å›:
            æŒ‰å¹³å°ç»„ç»‡çš„æ•°æ®å­—å…¸
        """
        results = {}
        
        for platform, fetcher in self.fetchers.items():
            try:
                data = fetcher.fetch_comprehensive_data(symbol, **kwargs)
                results[platform] = data
                self.logger.info(f"ä» {platform} è·å–æ•°æ®æˆåŠŸ: {len(data.posts)} æ¡å¸–å­")
            except Exception as e:
                self.logger.error(f"ä» {platform} è·å–æ•°æ®å¤±è´¥: {e}")
                results[platform] = None
        
        return results
    
    def aggregate_sentiment(self,
                          symbol: str,
                          **kwargs) -> Dict[str, Any]:
        """
        èšåˆå¤šä¸ªå¹³å°çš„æƒ…ç»ªåˆ†æ
        
        å‚æ•°:
            symbol: åŠ å¯†è´§å¸ç¬¦å·
            **kwargs: é¢å¤–å‚æ•°
            
        è¿”å›:
            èšåˆçš„æƒ…ç»ªåˆ†æç»“æœ
        """
        platform_data = self.fetch_multi_platform_data(symbol, **kwargs)
        
        # èšåˆæƒ…ç»ª
        total_sentiment_score = 0.0
        total_posts = 0
        platform_sentiments = {}
        
        for platform, data in platform_data.items():
            if data and data.sentiment:
                platform_sentiments[platform] = {
                    'sentiment': data.sentiment.overall_sentiment,
                    'score': data.sentiment.sentiment_score,
                    'post_count': len(data.posts),
                    'confidence': data.sentiment.confidence
                }
                
                total_sentiment_score += data.sentiment.sentiment_score
                total_posts += len(data.posts)
        
        # è®¡ç®—åŠ æƒå¹³å‡
        if platform_sentiments:
            avg_sentiment = total_sentiment_score / len(platform_sentiments)
            overall_sentiment = 'positive' if avg_sentiment > 0.2 else 'negative' if avg_sentiment < -0.2 else 'neutral'
        else:
            avg_sentiment = 0.0
            overall_sentiment = 'neutral'
        
        return {
            'symbol': symbol,
            'overall_sentiment': overall_sentiment,
            'aggregated_score': avg_sentiment,
            'total_posts': total_posts,
            'platform_count': len(platform_sentiments),
            'platform_sentiments': platform_sentiments,
            'timestamp': datetime.now()
        }
    
    def get_status(self) -> Dict[str, Any]:
        """è·å–çŠ¶æ€"""
        status = {
            'platforms': self.platforms,
            'is_initialized': self.is_initialized,
            'fetcher_status': {}
        }
        
        for platform, fetcher in self.fetchers.items():
            status['fetcher_status'][platform] = fetcher.get_status()
        
        return status
    
    def close(self):
        """å…³é—­æ‰€æœ‰è·å–å™¨"""
        for platform, fetcher in self.fetchers.items():
            try:
                fetcher.close()
                self.logger.info(f"å…³é—­ {platform} è·å–å™¨æˆåŠŸ")
            except Exception as e:
                self.logger.error(f"å…³é—­ {platform} è·å–å™¨å¤±è´¥: {e}")
        
        self.is_initialized = False


# ==================== æµ‹è¯•å‡½æ•° ====================

def test_social_fetcher():
    """æµ‹è¯•ç¤¾äº¤åª’ä½“è·å–å™¨"""
    print("=" * 60)
    print("ç¤¾äº¤åª’ä½“è·å–å™¨æ¨¡å—æµ‹è¯•")
    print("=" * 60)
    
    # æµ‹è¯•åŸºç¡€åŠŸèƒ½
    print("\n1. æµ‹è¯•åŸºç¡€ç¤¾äº¤åª’ä½“è·å–å™¨:")
    
    try:
        # åˆ›å»ºæµ‹è¯•è·å–å™¨ï¼ˆä¸ä½¿ç”¨çœŸå®APIå¯†é’¥ï¼‰
        fetcher = BaseSocialFetcher(
            name="test_social",
            platform="twitter",
            config={
                'max_posts': 10,
                'keywords': ['bitcoin', 'crypto'],
                'symbols': ['BTC', 'ETH'],
                'sentiment_enabled': True
            }
        )
        
        print(f"âœ… è·å–å™¨åˆ›å»ºæˆåŠŸ: {fetcher.name}")
        
        # æµ‹è¯•çŠ¶æ€è·å–
        status = fetcher.get_status()
        print(f"âœ… çŠ¶æ€è·å–æˆåŠŸ: {status['platform']}")
        
        # æµ‹è¯•ç¬¦å·éªŒè¯
        test_symbol = "BTC"
        is_valid = fetcher.validate_symbol(test_symbol)
        print(f"âœ… ç¬¦å·éªŒè¯: {test_symbol} -> {is_valid}")
        
        # æµ‹è¯•ç¬¦å·æ ¼å¼åŒ–
        formatted = fetcher.format_symbol("btc-usdt")
        print(f"âœ… ç¬¦å·æ ¼å¼åŒ–: btc-usdt -> {formatted}")
        
        # æµ‹è¯•æŸ¥è¯¢æ„å»º
        query = fetcher._build_query_from_symbol("BTC")
        print(f"âœ… æŸ¥è¯¢æ„å»º: BTC -> {query}")
        
        # æµ‹è¯•æƒ…ç»ªåˆ†æ
        text = "Bitcoin is going to the moon! ğŸš€"
        sentiment, score = fetcher._analyze_sentiment(text)
        print(f"âœ… æƒ…ç»ªåˆ†æ: '{text}' -> {sentiment} ({score:.2f})")
        
        # æµ‹è¯•ç¬¦å·æå–
        text_with_symbols = "I love $BTC and $ETH! #crypto"
        symbols = fetcher._extract_symbols(text_with_symbols)
        print(f"âœ… ç¬¦å·æå–: '{text_with_symbols}' -> {symbols}")
        
        # æµ‹è¯•æ—¶é—´æˆ³è§£æ
        timestamp = datetime.now()
        parsed = fetcher.parse_timestamp(timestamp)
        print(f"âœ… æ—¶é—´æˆ³è§£æ: {timestamp} -> {parsed}")
        
        # æµ‹è¯•å¯ç”¨ç¬¦å·
        available_symbols = fetcher.get_available_symbols()
        print(f"âœ… å¯ç”¨ç¬¦å·: {available_symbols}")
        
        # å…³é—­è·å–å™¨
        fetcher.close()
        print("âœ… è·å–å™¨å…³é—­æˆåŠŸ")
        
    except Exception as e:
        print(f"âŒ åŸºç¡€æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
    
    # æµ‹è¯•å¤šå¹³å°è·å–å™¨
    print("\n2. æµ‹è¯•å¤šå¹³å°ç¤¾äº¤åª’ä½“è·å–å™¨:")
    
    try:
        multi_fetcher = MultiPlatformSocialFetcher(
            platforms=["twitter", "reddit"],
            config={
                'twitter': {'max_posts': 5},
                'reddit': {'max_posts': 5}
            }
        )
        
        print(f"âœ… å¤šå¹³å°è·å–å™¨åˆ›å»ºæˆåŠŸ: {multi_fetcher.platforms}")
        
        # åˆå§‹åŒ–
        initialized = multi_fetcher.initialize()
        print(f"âœ… åˆå§‹åŒ–ç»“æœ: {initialized}")
        
        # è·å–çŠ¶æ€
        status = multi_fetcher.get_status()
        print(f"âœ… å¤šå¹³å°çŠ¶æ€: {len(status['fetcher_status'])} ä¸ªå¹³å°")
        
        # æ³¨æ„ï¼šè¿™é‡Œä¸å®é™…è·å–æ•°æ®ï¼Œå› ä¸ºéœ€è¦APIå¯†é’¥
        print("âš ï¸  å®é™…æ•°æ®è·å–éœ€è¦APIå¯†é’¥é…ç½®")
        
        # å…³é—­
        multi_fetcher.close()
        print("âœ… å¤šå¹³å°è·å–å™¨å…³é—­æˆåŠŸ")
        
    except Exception as e:
        print(f"âŒ å¤šå¹³å°æµ‹è¯•å¤±è´¥: {e}")
    
    # æ¼”ç¤ºé…ç½®ç¤ºä¾‹
    print("\n3. é…ç½®ç¤ºä¾‹:")
    print("Twitteré…ç½®ç¤ºä¾‹:")
    print("""
    twitter_config = {
        'twitter_api_key': 'YOUR_API_KEY',
        'twitter_api_secret': 'YOUR_API_SECRET',
        'twitter_access_token': 'YOUR_ACCESS_TOKEN',
        'twitter_access_secret': 'YOUR_ACCESS_SECRET',
        'twitter_bearer_token': 'YOUR_BEARER_TOKEN',
        'max_posts': 100,
        'rate_limit': 1.0
    }
    """)
    
    print("Reddité…ç½®ç¤ºä¾‹:")
    print("""
    reddit_config = {
        'reddit_client_id': 'YOUR_CLIENT_ID',
        'reddit_client_secret': 'YOUR_CLIENT_SECRET',
        'reddit_user_agent': 'CryptoSocialFetcher/1.0',
        'max_posts': 100,
        'rate_limit': 1.0
    }
    """)
    
    print("\nâœ… ç¤¾äº¤åª’ä½“è·å–å™¨æ¨¡å—æµ‹è¯•å®Œæˆ")


# ==================== ä¸»ç¨‹åºå…¥å£ ====================

if __name__ == "__main__":
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # è¿è¡Œæµ‹è¯•
    test_social_fetcher()